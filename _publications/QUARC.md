---
title: "QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech Classification"
collection: publications
permalink: https://ieeexplore.ieee.org/document/9373102
excerpt: 'This paper is about using Quaternion Neural Networks for hate speech classification using multi-modal data.'
date: 2009-10-01
venue: '2021 IEEE International Conference on Big Data and Smart Computing (BigComp)'
paperurl: 'https://ieeexplore.ieee.org/document/9373102'
citation: 'D. Kumar, N. Kumar and S. Mishra, "QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech Classification," 2021 IEEE International Conference on Big Data and Smart Computing (BigComp), Jeju Island, Korea (South), 2021, pp. 346-349, doi: 10.1109/BigComp51126.2021.00075.'
---
Hate speech, quite common in the age of social media, at times harmless but can also cause mental trauma to someone or even riots in communities. Image of a religious symbol with derogatory comment or video of a man abusing a particular community, all become hate speech with its every modality (such as text, image, and audio) contributing towards it. Models based on a particular modality of hate speech post on social media are not useful, rather, we need models like multimodal fusion models that consider both image and text while classifying hate speech. Text-image fusion models are heavily parameterized, hence we propose a quaternion neural network-based model having additional fusion components for each pair of modalities. The Model is tested on the MMHS150K twitter dataset for hate speech classification. The model shows an almost 75% reduction in parameters and also benefits us in terms of storage space and training time while being at par in terms of performance as compared to its real counterpart.

[Download paper here](https://arxiv.org/pdf/2012.08312)
